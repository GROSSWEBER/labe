# Illustration

Acquire a subset of the citation graph and generate a visualization.

```
Exploiting Contextual Word Embed  2021  =>  Citation Intent Classification U  2021
Adapting Open Domain Fact Extrac  2020  =>  Don't Stop Pretraining: Adapt La  2020
ERNIE: A Data Platform For Resea  2018  =>  Methodology for Evaluating Citat  2013
COVIDLies: Detecting COVID-19 Mi  2020  =>  Don't Stop Pretraining: Adapt La  2020
SMOTE-DRNN: A Deep Learning Algo  2021  =>  Machine Learning: Algorithms, Re  2021
Predicting the Reproducibility o  2021  =>  Acknowledgement Entity Recogniti  2020
Towards Zero-Shot Multilingual S  2021  =>  Don't Stop Pretraining: Adapt La  2020
Hashtag# Perspicacity of India R  2018  =>  Large Scale Citation Matching Us  2013
Self-Diagnosis and Self-Debiasin  2021  =>  Don't Stop Pretraining: Adapt La  2020
A Dataset of Information-Seeking  2021  =>  S2ORC: The Semantic Scholar Open  2020
Char2Subword: Extending the Subw  2021  =>  Don't Stop Pretraining: Adapt La  2020
S2ORC: The Semantic Scholar Open  2020  =>  Machine Learning vs. Rules and O  2018
CUPID: Adaptive Curation of Pre-  2021  =>  Don't Stop Pretraining: Adapt La  2020
Multilevel Text Alignment with C  2020  =>  S2ORC: The Semantic Scholar Open  2020
A Large-Scale Analysis of Cross-  2020  =>  S2ORC: The Semantic Scholar Open  2020
AllenAct: A Framework for Embodi  2020  =>  S2ORC: The Semantic Scholar Open  2020
Neural Unsupervised Domain Adapt  2020  =>  Don't Stop Pretraining: Adapt La  2020
Deep Learning applications for C  2021  =>  Don't Stop Pretraining: Adapt La  2020
Chrum: The Tool for Convenient G  2014  =>  Large Scale Citation Matching Us  2013
Collaborative and Clustering Bas  MISS  =>  Large Scale Citation Matching Us  2013
COVID-19: Worldwide Profiles dur  2021  =>  Deep Learning applications for C  2021
An Anatomization of Aadhaar Card  2016  =>  Large Scale Citation Matching Us  2013
Augmenting Scientific Papers wit  2021  =>  Document-Level Definition Detect  2020
UCPhrase: Unsupervised Context-a  2021  =>  Don't Stop Pretraining: Adapt La  2020
Effective Unsupervised Domain Ad  2020  =>  Don't Stop Pretraining: Adapt La  2020
Framing Unpacked: A Semi-Supervi  2021  =>  Don't Stop Pretraining: Adapt La  2020
Content Analysis of Scientific A  2014  =>  Large Scale Citation Matching Us  2013
Analysing the Requirements for a  2021  =>  S2ORC: The Semantic Scholar Open  2020
SChuBERT: Scholarly Document Chu  2020  =>  S2ORC: The Semantic Scholar Open  2020
Large Scale Citation Matching Us  2013  =>  Methodology for Evaluating Citat  2013
Human Speaker Recognition Based   2021  =>  Review of deep learning: concept  2021
Using Pre-Trained Transformer fo  2020  =>  TLDR: Extreme Summarization of S  2020
Machine Learning: Algorithms, Re  2021  =>  Deep Learning applications for C  2021
Acknowledgement Entity Recogniti  2020  =>  S2ORC: The Semantic Scholar Open  2020
Applications of Artificial Intel  2021  =>  Deep Learning applications for C  2021
What Disease does this Patient H  2020  =>  Don't Stop Pretraining: Adapt La  2020
Scaling Classroom Education with  2020  =>  Don't Stop Pretraining: Adapt La  2020
Document-Level Definition Detect  2020  =>  S2ORC: The Semantic Scholar Open  2020
CausaLM: Causal Model Explanatio  2021  =>  Don't Stop Pretraining: Adapt La  2020
Learning an Effective Context-Re  2020  =>  Don't Stop Pretraining: Adapt La  2020
```
